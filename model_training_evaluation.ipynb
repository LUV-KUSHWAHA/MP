{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a160120",
   "metadata": {},
   "source": [
    "# Café Location Suitability Model Training & Evaluation\n",
    "\n",
    "This notebook demonstrates the complete machine learning pipeline for predicting café location suitability in Kathmandu:\n",
    "\n",
    "1. **Data Loading**: Load the preprocessed training dataset\n",
    "2. **Train/Test Split**: Split data into 80% training and 20% testing sets\n",
    "3. **Model Training**: Train a Random Forest classifier on the training data\n",
    "4. **Model Evaluation**: Test the model and calculate performance metrics\n",
    "\n",
    "**Dataset**: Preprocessed training data with balanced classes and selected features\n",
    "**Target**: Location suitability (High/Medium/Low)\n",
    "**Algorithm**: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a65aaed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7e28a",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Load the preprocessed training dataset and examine its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c3d89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Shape: 2676 rows × 14 columns\n",
      "\n",
      "Columns:\n",
      " 1. competitors_min_distance\n",
      " 2. roads_within_500m\n",
      " 3. roads_avg_distance\n",
      " 4. schools_within_500m\n",
      " 5. schools_within_200m\n",
      " 6. schools_min_distance\n",
      " 7. hospitals_within_500m\n",
      " 8. hospitals_min_distance\n",
      " 9. population_density_proxy\n",
      "10. accessibility_score\n",
      "11. foot_traffic_score\n",
      "12. suitability\n",
      "13. latitude\n",
      "14. longitude\n",
      "\n",
      "Suitability class distribution:\n",
      "suitability\n",
      "Low       892\n",
      "High      892\n",
      "Medium    892\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data types:\n",
      "competitors_min_distance    float64\n",
      "roads_within_500m           float64\n",
      "roads_avg_distance          float64\n",
      "schools_within_500m         float64\n",
      "schools_within_200m         float64\n",
      "schools_min_distance        float64\n",
      "hospitals_within_500m       float64\n",
      "hospitals_min_distance      float64\n",
      "population_density_proxy    float64\n",
      "accessibility_score         float64\n",
      "foot_traffic_score          float64\n",
      "suitability                     str\n",
      "latitude                    float64\n",
      "longitude                   float64\n",
      "dtype: object\n",
      "\n",
      "Missing values: 0\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitors_min_distance</th>\n",
       "      <th>roads_within_500m</th>\n",
       "      <th>roads_avg_distance</th>\n",
       "      <th>schools_within_500m</th>\n",
       "      <th>schools_within_200m</th>\n",
       "      <th>schools_min_distance</th>\n",
       "      <th>hospitals_within_500m</th>\n",
       "      <th>hospitals_min_distance</th>\n",
       "      <th>population_density_proxy</th>\n",
       "      <th>accessibility_score</th>\n",
       "      <th>foot_traffic_score</th>\n",
       "      <th>suitability</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.729106</td>\n",
       "      <td>-0.678142</td>\n",
       "      <td>0.904368</td>\n",
       "      <td>-0.667650</td>\n",
       "      <td>-0.465293</td>\n",
       "      <td>0.966992</td>\n",
       "      <td>-0.498428</td>\n",
       "      <td>0.520655</td>\n",
       "      <td>-0.683634</td>\n",
       "      <td>-0.697804</td>\n",
       "      <td>-0.696368</td>\n",
       "      <td>Low</td>\n",
       "      <td>27.664030</td>\n",
       "      <td>85.353726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.729106</td>\n",
       "      <td>-0.678142</td>\n",
       "      <td>0.904368</td>\n",
       "      <td>-0.667650</td>\n",
       "      <td>-0.465293</td>\n",
       "      <td>0.966992</td>\n",
       "      <td>-0.498428</td>\n",
       "      <td>0.520655</td>\n",
       "      <td>-0.683634</td>\n",
       "      <td>-0.697804</td>\n",
       "      <td>-0.696368</td>\n",
       "      <td>Low</td>\n",
       "      <td>27.748368</td>\n",
       "      <td>85.278061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.729106</td>\n",
       "      <td>-0.678142</td>\n",
       "      <td>0.904368</td>\n",
       "      <td>-0.667650</td>\n",
       "      <td>-0.465293</td>\n",
       "      <td>0.966992</td>\n",
       "      <td>-0.498428</td>\n",
       "      <td>0.520655</td>\n",
       "      <td>-0.683634</td>\n",
       "      <td>-0.697804</td>\n",
       "      <td>-0.696368</td>\n",
       "      <td>Low</td>\n",
       "      <td>27.732894</td>\n",
       "      <td>85.277918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.729106</td>\n",
       "      <td>-0.678142</td>\n",
       "      <td>0.904368</td>\n",
       "      <td>-0.667650</td>\n",
       "      <td>-0.465293</td>\n",
       "      <td>0.966992</td>\n",
       "      <td>-0.498428</td>\n",
       "      <td>0.520655</td>\n",
       "      <td>-0.683634</td>\n",
       "      <td>-0.697804</td>\n",
       "      <td>-0.696368</td>\n",
       "      <td>Low</td>\n",
       "      <td>27.724335</td>\n",
       "      <td>85.275551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.729106</td>\n",
       "      <td>-0.493570</td>\n",
       "      <td>-3.239842</td>\n",
       "      <td>0.407154</td>\n",
       "      <td>1.266451</td>\n",
       "      <td>-1.711839</td>\n",
       "      <td>-0.498428</td>\n",
       "      <td>0.520655</td>\n",
       "      <td>0.134359</td>\n",
       "      <td>0.691612</td>\n",
       "      <td>0.560886</td>\n",
       "      <td>High</td>\n",
       "      <td>27.730741</td>\n",
       "      <td>85.295011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   competitors_min_distance  roads_within_500m  roads_avg_distance  \\\n",
       "0                  0.729106          -0.678142            0.904368   \n",
       "1                  0.729106          -0.678142            0.904368   \n",
       "2                  0.729106          -0.678142            0.904368   \n",
       "3                  0.729106          -0.678142            0.904368   \n",
       "4                  0.729106          -0.493570           -3.239842   \n",
       "\n",
       "   schools_within_500m  schools_within_200m  schools_min_distance  \\\n",
       "0            -0.667650            -0.465293              0.966992   \n",
       "1            -0.667650            -0.465293              0.966992   \n",
       "2            -0.667650            -0.465293              0.966992   \n",
       "3            -0.667650            -0.465293              0.966992   \n",
       "4             0.407154             1.266451             -1.711839   \n",
       "\n",
       "   hospitals_within_500m  hospitals_min_distance  population_density_proxy  \\\n",
       "0              -0.498428                0.520655                 -0.683634   \n",
       "1              -0.498428                0.520655                 -0.683634   \n",
       "2              -0.498428                0.520655                 -0.683634   \n",
       "3              -0.498428                0.520655                 -0.683634   \n",
       "4              -0.498428                0.520655                  0.134359   \n",
       "\n",
       "   accessibility_score  foot_traffic_score suitability   latitude  longitude  \n",
       "0            -0.697804           -0.696368         Low  27.664030  85.353726  \n",
       "1            -0.697804           -0.696368         Low  27.748368  85.278061  \n",
       "2            -0.697804           -0.696368         Low  27.732894  85.277918  \n",
       "3            -0.697804           -0.696368         Low  27.724335  85.275551  \n",
       "4             0.691612            0.560886        High  27.730741  85.295011  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the preprocessed training dataset\n",
    "data_path = 'cafelocate/data/preprocessed_training_dataset.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "print(\"\\nColumns:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nSuitability class distribution:\")\n",
    "print(df['suitability'].value_counts())\n",
    "\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a9832",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split (80/20)\n",
    "\n",
    "Split the dataset into training (80%) and testing (20%) sets using stratified sampling to maintain class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad606f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected:\n",
      " 1. competitors_min_distance\n",
      " 2. roads_within_500m\n",
      " 3. roads_avg_distance\n",
      " 4. schools_within_500m\n",
      " 5. schools_within_200m\n",
      " 6. schools_min_distance\n",
      " 7. hospitals_within_500m\n",
      " 8. hospitals_min_distance\n",
      " 9. population_density_proxy\n",
      "10. accessibility_score\n",
      "11. foot_traffic_score\n",
      "\n",
      "Target variable: suitability\n",
      "Classes: ['High', 'Low', 'Medium']\n",
      "\n",
      "Data split completed:\n",
      "Training set: 2140 samples (80.0%)\n",
      "Test set: 536 samples (20.0%)\n",
      "\n",
      "Training set class distribution:\n",
      "suitability\n",
      "High      714\n",
      "Low       713\n",
      "Medium    713\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set class distribution:\n",
      "suitability\n",
      "Low       179\n",
      "Medium    179\n",
      "High      178\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "feature_cols = [\n",
    "    'competitors_min_distance', 'roads_within_500m', 'roads_avg_distance',\n",
    "    'schools_within_500m', 'schools_within_200m', 'schools_min_distance',\n",
    "    'hospitals_within_500m', 'hospitals_min_distance',\n",
    "    'population_density_proxy', 'accessibility_score', 'foot_traffic_score'\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['suitability']\n",
    "\n",
    "print(\"Features selected:\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nTarget variable: suitability\")\n",
    "print(f\"Classes: {sorted(y.unique())}\")\n",
    "\n",
    "# Split the data (80% train, 20% test) with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y  # Maintain class balance\n",
    ")\n",
    "\n",
    "print(\"\\nData split completed:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e763ca7",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "Train a Random Forest classifier on the training dataset with optimized hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9274e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoding:\n",
      "  0: High\n",
      "  1: Low\n",
      "  2: Medium\n",
      "\n",
      "Training Random Forest model...\n",
      "Model training completed!\n",
      "Number of trees: 200\n",
      "Maximum depth: 15\n",
      "Number of features: 11\n",
      "\n",
      "Top 5 most important features:\n",
      "                     feature  importance\n",
      "10        foot_traffic_score    0.288439\n",
      "8   population_density_proxy    0.255146\n",
      "3        schools_within_500m    0.149390\n",
      "5       schools_min_distance    0.121529\n",
      "6      hospitals_within_500m    0.038179\n"
     ]
    }
   ],
   "source": [
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(\"Label encoding:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {i}: {label}\")\n",
    "\n",
    "# Initialize and train Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,      # Number of trees\n",
    "    max_depth=15,          # Maximum depth of trees\n",
    "    min_samples_split=5,   # Minimum samples to split\n",
    "    min_samples_leaf=2,    # Minimum samples per leaf\n",
    "    random_state=42,       # For reproducibility\n",
    "    class_weight='balanced', # Handle any remaining imbalance\n",
    "    n_jobs=-1              # Use all available cores\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Random Forest model...\")\n",
    "rf_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "print(\"Model training completed!\")\n",
    "print(f\"Number of trees: {rf_model.n_estimators}\")\n",
    "print(f\"Maximum depth: {rf_model.max_depth}\")\n",
    "print(f\"Number of features: {rf_model.n_features_in_}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "print(feature_importance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b76bc36",
   "metadata": {},
   "source": [
    "## 4. Model Testing & Evaluation\n",
    "\n",
    "Test the trained model on the unseen test dataset and calculate performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4582833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions completed!\n",
      "Test set size: 536 samples\n",
      ".4f\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.99      0.99      0.99       178\n",
      "         Low       1.00      1.00      1.00       179\n",
      "      Medium       0.99      0.99      0.99       179\n",
      "\n",
      "    accuracy                           1.00       536\n",
      "   macro avg       1.00      1.00      1.00       536\n",
      "weighted avg       1.00      1.00      1.00       536\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted →\n",
      "Actual ↓\n",
      "        High  Low  Medium\n",
      "High     177    0       1\n",
      "Low        0  179       0\n",
      "Medium     1    0     178\n",
      "\n",
      "Additional Metrics:\n",
      "Macro-averaged F1-score: 0.9963\n",
      "Weighted-averaged F1-score: 0.9963\n",
      "Error rate: 0.0037\n",
      "\n",
      "Error Analysis:\n",
      "Total predictions: 536\n",
      "Correct predictions: 534\n",
      "Incorrect predictions: 2\n",
      "Error rate for 'High': 0.0056\n",
      "Error rate for 'Low': 0.0000\n",
      "Error rate for 'Medium': 0.0056\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "y_pred_encoded = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)\n",
    "\n",
    "# Decode predictions back to labels\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "print(\"Predictions completed!\")\n",
    "print(f\"Test set size: {len(y_test)} samples\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\".4f\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"Predicted →\")\n",
    "print(\"Actual ↓\")\n",
    "cm_df = pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
    "print(cm_df)\n",
    "\n",
    "# Additional metrics\n",
    "print(\"\\nAdditional Metrics:\")\n",
    "print(f\"Macro-averaged F1-score: {classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"Weighted-averaged F1-score: {classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "# Error analysis\n",
    "errors = y_test != y_pred\n",
    "error_rate = errors.sum() / len(y_test)\n",
    "print(f\"Error rate: {error_rate:.4f}\")\n",
    "\n",
    "print(\"\\nError Analysis:\")\n",
    "print(f\"Total predictions: {len(y_test)}\")\n",
    "print(f\"Correct predictions: {(~errors).sum()}\")\n",
    "print(f\"Incorrect predictions: {errors.sum()}\")\n",
    "\n",
    "# Per-class error rates\n",
    "for class_name in label_encoder.classes_:\n",
    "    class_mask = y_test == class_name\n",
    "    class_errors = errors[class_mask]\n",
    "    class_error_rate = class_errors.sum() / class_mask.sum() if class_mask.sum() > 0 else 0\n",
    "    print(f\"Error rate for '{class_name}': {class_error_rate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca81e80",
   "metadata": {},
   "source": [
    "## 5. Model Summary & Key Findings\n",
    "\n",
    "### Performance Summary\n",
    "- **Overall Accuracy**: 99.63%\n",
    "- **Best Performing Class**: Low suitability (100% accuracy)\n",
    "- **Most Challenging Class**: High & Medium suitability (99.44% accuracy each)\n",
    "- **Key Insights**: Model achieves near-perfect performance with only 2 misclassifications out of 536 test samples\n",
    "\n",
    "### Model Characteristics\n",
    "- **Algorithm**: Random Forest Classifier\n",
    "- **Training Samples**: 2,140 (80% of 2,676)\n",
    "- **Test Samples**: 536 (20% of 2,676)\n",
    "- **Features Used**: 11 selected features\n",
    "- **Classes**: High, Medium, Low suitability\n",
    "\n",
    "### Recommendations\n",
    "- **Deployment Ready**: Model shows excellent performance and is ready for production use\n",
    "- **Monitoring**: Implement continuous monitoring for performance drift\n",
    "- **Feature Engineering**: Consider additional temporal features if available\n",
    "- **Scalability**: Model is lightweight and suitable for real-time predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84de7fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Model path: cafelocate/ml/models\\final_suitability_rf_model.pkl\n",
      "Encoder path: cafelocate/ml/models\\final_suitability_label_encoder.pkl\n",
      "Feature importance saved: cafelocate/ml/models\\feature_importance.csv\n",
      "\n",
      "Notebook execution completed!\n",
      "The trained model is ready for deployment in the CaféLocate system.\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model and encoder for deployment\n",
    "models_dir = 'cafelocate/ml/models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(models_dir, 'final_suitability_rf_model.pkl')\n",
    "encoder_path = os.path.join(models_dir, 'final_suitability_label_encoder.pkl')\n",
    "\n",
    "joblib.dump(rf_model, model_path)\n",
    "joblib.dump(label_encoder, encoder_path)\n",
    "\n",
    "print(\"Model saved successfully!\")\n",
    "print(f\"Model path: {model_path}\")\n",
    "print(f\"Encoder path: {encoder_path}\")\n",
    "\n",
    "# Save feature importance for reference\n",
    "importance_path = os.path.join(models_dir, 'feature_importance.csv')\n",
    "feature_importance.to_csv(importance_path, index=False)\n",
    "print(f\"Feature importance saved: {importance_path}\")\n",
    "\n",
    "print(\"\\nNotebook execution completed!\")\n",
    "print(\"The trained model is ready for deployment in the CaféLocate system.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
